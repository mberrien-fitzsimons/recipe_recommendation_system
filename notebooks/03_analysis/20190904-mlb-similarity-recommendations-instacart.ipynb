{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Rules - Similarity: Instacart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Combine the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Modules as Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://surprise.readthedocs.io/en/stable/similarities.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = pd.read_csv('../../data/05_model_output/baskets_newprodlist_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((baskets['new_prod_list']!='1')&(baskets['new_prod_list']!='100')&(baskets['new_prod_list']!='11')&(baskets['new_prod_list']!='118')&(baskets['new_prod_list']!='2')&(baskets['new_prod_list']!='24')&(baskets['new_prod_list']!='3')&(baskets['new_prod_list']!='3 cheese')&(baskets['new_prod_list']!='30')&(baskets['new_prod_list']!='328')&(baskets['new_prod_list']!='4')&(baskets['new_prod_list']!='5')&(baskets['new_prod_list']!='50')&(baskets['new_prod_list']!='6')&(baskets['new_prod_list']!='6 cheese')&(baskets['new_prod_list']!='60')&(baskets['new_prod_list']!='7')&(baskets['new_prod_list']!='70')&(baskets['new_prod_list']!='8')&(baskets['new_prod_list']!='85')&(baskets['new_prod_list']!='9')&(baskets['new_prod_list']!='95')&(baskets['new_prod_list']!='97')&(baskets['new_prod_list']!='98')&(baskets['new_prod_list']!='a')&(baskets['new_prod_list']!='a garlic butter sauce')&(baskets['new_prod_list']!=np.nan)&(baskets['new_prod_list']!='nan'))\n",
    "baskets = baskets[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the new product list made from my crf model reduced the number of products from 24K to just over 4k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Products After Running Names through CRF Mode: ',baskets.new_prod_list.nunique())\n",
    "print('Number of products in the original list: ',baskets.product_name.nunique())\n",
    "print('Number of unique users: ',baskets.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 200k unique users. Since this is too much for my computer to handle I am going to take a subsample of 50k users and go from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_users_lst = list(baskets.user_id.unique())\n",
    "len(insta_users_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a random sample of 100k of these user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_usrids_100k = random.sample(insta_users_lst, 100000)\n",
    "mask = baskets['user_id'].isin(random_usrids_100k)\n",
    "baskets_100k = baskets.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of User IDs: ',baskets_100k.user_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's drop columns and get everything into the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.drop(columns=['user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.reset_index(inplace=True)\n",
    "baskets_100k.dropna(inplace=True)\n",
    "baskets_100k.new_prod_list.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### break things up into 10k different products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep getting a unstack overflow error from having too many things. Let's break up the dataset further into types of products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = list(baskets_100k.new_prod_list.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product List 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the index and old product name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_complete = baskets_100k.drop(columns=['index', 'product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_1 = product_list[:1000]\n",
    "mask_prod1 = baskets_complete['new_prod_list'].isin(product_list_1)\n",
    "baskets_prod1 = baskets_complete.loc[mask_prod1]\n",
    "# pivot the dataset\n",
    "basket_matrix_1 = (baskets_prod1.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_2 = product_list[1000:2000]\n",
    "mask_prod2 = baskets_complete['new_prod_list'].isin(product_list_2)\n",
    "baskets_prod2 = baskets_complete.loc[mask_prod2]\n",
    "# pivot the dataset\n",
    "basket_matrix_2 = (baskets_prod2.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_3 = product_list[2000:3000]\n",
    "mask_prod3 = baskets_complete['new_prod_list'].isin(product_list_3)\n",
    "baskets_prod3 = baskets_complete.loc[mask_prod3]\n",
    "# pivot the dataset\n",
    "basket_matrix_3 = (baskets_prod3.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_4 = product_list[3000:]\n",
    "mask_prod4 = baskets_complete['new_prod_list'].isin(product_list_4)\n",
    "baskets_prod4 = baskets_complete.loc[mask_prod4]\n",
    "# pivot the dataset\n",
    "basket_matrix_4 = (baskets_prod4.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's merge all the small dataframes into a large one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basket_matrix_1.shape)\n",
    "print(basket_matrix_2.shape)\n",
    "print(basket_matrix_3.shape)\n",
    "print(basket_matrix_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = basket_matrix_1.merge(basket_matrix_2, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = matrix1.merge(basket_matrix_3, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_matrix_usr = matrix2.merge(basket_matrix_4, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_matrix_usr.to_csv('../../data/03_processed/basket_matrix_usr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model in a file located in src data folder and read the result into the data 05_model output folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item-item calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(data_items):\n",
    "    \"\"\"Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    sim = pd.DataFrame(data=similarities, index= data_items.columns, columns= data_items.columns)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = pd.read_csv('../../data/05_model_output/data_matrix_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potato     1.000000\n",
      "onion      0.120991\n",
      "milk       0.107052\n",
      "tomato     0.106734\n",
      "carrots    0.101938\n",
      "cheese     0.098204\n",
      "garlic     0.097276\n",
      "avocado    0.096195\n",
      "eggs       0.092582\n",
      "apple      0.092447\n",
      "butter     0.092278\n",
      "Name: potato, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data_matrix.loc['potato'].nlargest(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user-item model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:947: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    }
   ],
   "source": [
    "# Construct a new dataframe with the 10 closest neighbours (most similar)\n",
    "# for each artist.\n",
    "data_neighbours = pd.DataFrame(index=data_matrix.columns, columns=range(1,11))\n",
    "for i in range(0, len(data_matrix.columns)):\n",
    "    data_neighbours.ix[i,:10] = data_matrix.ix[0:,i].sort_values(ascending=False)[:10].index\n",
    "# Get the artists the user has played.\n",
    "known_user_likes = ['avocados', 'blueberries', 'bell pepper', 'onions', 'chicken', 'beef', 'chocolate']\n",
    "\n",
    "# Construct the neighbourhood from the most similar items to the\n",
    "# ones our user has already liked.\n",
    "most_similar_to_likes = data_neighbours.loc[known_user_likes]\n",
    "similar_list = most_similar_to_likes.values.tolist()\n",
    "similar_list = list(set([item for sublist in similar_list for item in sublist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**:\n",
    "\n",
    "* https://medium.com/datadriveninvestor/how-to-build-a-recommendation-system-for-purchase-data-step-by-step-d6d7a78800b6\n",
    "* http://www.moorissatjokro.com/#home\n",
    "* https://towardsdatascience.com/how-to-build-a-simple-recommender-system-in-python-375093c3fb7d\n",
    "* **Possible Algorithm to use**: https://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering\n",
    "* **Similairity Models**: https://surprise.readthedocs.io/en/stable/similarities.html\n",
    "* **Association Rule Learning**: https://en.wikipedia.org/wiki/Association_rule_learning\n",
    "* collaborative filtering item - item article medium: https://medium.com/radon-dev/item-item-collaborative-filtering-with-binary-or-unary-data-e8f0b465b2c3\n",
    "* **How to use Pyspark and AWS**: https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921\n",
    "* **association rule algorithm**: https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "* **appriori**: https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "\n",
    "***\n",
    "* **Practical Business Python**: https://pbpython.com/market-basket-analysis.html\n",
    "* **Market Basket Analysis Notebook**: https://github.com/chris1610/pbpython/blob/master/notebooks/Market_Basket_Intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory-based methods**\n",
    "1. **User-based collaborative filtering**: In this model products are recommended to a user based on the fact that the products have been liked by users similar to the user. For example if Derrick and Dennis like the same movies and a new movie comes out that Derick likes,then we can recommend that movie to Dennis because Derrick and Dennis seem to like the same movies.\n",
    "1. **Item-based collaborative filtering**: These systems identify similar items based on usersâ€™ previous ratings. For example if users A,B and C gave a 5 star rating to books X and Y then when a user D buys book Y they also get a recommendation to purchase book X because the system identifies book X and Y as similar based on the ratings of users A,B and C."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
