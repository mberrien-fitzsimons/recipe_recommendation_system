{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Rules - Similarity: Instacart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Combine the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Modules as Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://surprise.readthedocs.io/en/stable/similarities.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = pd.read_csv('../../data/05_model_output/baskets_newprodlist_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((baskets['new_prod_list']!='1')&(baskets['new_prod_list']!='100')&(baskets['new_prod_list']!='11')&(baskets['new_prod_list']!='118')&(baskets['new_prod_list']!='2')&(baskets['new_prod_list']!='24')&(baskets['new_prod_list']!='3')&(baskets['new_prod_list']!='3 cheese')&(baskets['new_prod_list']!='30')&(baskets['new_prod_list']!='328')&(baskets['new_prod_list']!='4')&(baskets['new_prod_list']!='5')&(baskets['new_prod_list']!='50')&(baskets['new_prod_list']!='6')&(baskets['new_prod_list']!='6 cheese')&(baskets['new_prod_list']!='60')&(baskets['new_prod_list']!='7')&(baskets['new_prod_list']!='70')&(baskets['new_prod_list']!='8')&(baskets['new_prod_list']!='85')&(baskets['new_prod_list']!='9')&(baskets['new_prod_list']!='95')&(baskets['new_prod_list']!='97')&(baskets['new_prod_list']!='98')&(baskets['new_prod_list']!='a')&(baskets['new_prod_list']!='a garlic butter sauce')&(baskets['new_prod_list']!=np.nan)&(baskets['new_prod_list']!='nan'))\n",
    "baskets = baskets[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the new product list made from my crf model reduced the number of products from 24K to just over 4k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Products After Running Names through CRF Mode: ',baskets.new_prod_list.nunique())\n",
    "print('Number of products in the original list: ',baskets.product_name.nunique())\n",
    "print('Number of unique users: ',baskets.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 200k unique users. Since this is too much for my computer to handle I am going to take a subsample of 50k users and go from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_users_lst = list(baskets.user_id.unique())\n",
    "len(insta_users_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a random sample of 100k of these user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_usrids_100k = random.sample(insta_users_lst, 100000)\n",
    "mask = baskets['user_id'].isin(random_usrids_100k)\n",
    "baskets_100k = baskets.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of User IDs: ',baskets_100k.user_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's drop columns and get everything into the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.drop(columns=['user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_100k.reset_index(inplace=True)\n",
    "baskets_100k.dropna(inplace=True)\n",
    "baskets_100k.new_prod_list.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### break things up into 10k different products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep getting a unstack overflow error from having too many things. Let's break up the dataset further into types of products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = list(baskets_100k.new_prod_list.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product List 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the index and old product name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_complete = baskets_100k.drop(columns=['index', 'product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_1 = product_list[:1000]\n",
    "mask_prod1 = baskets_complete['new_prod_list'].isin(product_list_1)\n",
    "baskets_prod1 = baskets_complete.loc[mask_prod1]\n",
    "# pivot the dataset\n",
    "basket_matrix_1 = (baskets_prod1.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_2 = product_list[1000:2000]\n",
    "mask_prod2 = baskets_complete['new_prod_list'].isin(product_list_2)\n",
    "baskets_prod2 = baskets_complete.loc[mask_prod2]\n",
    "# pivot the dataset\n",
    "basket_matrix_2 = (baskets_prod2.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_3 = product_list[2000:3000]\n",
    "mask_prod3 = baskets_complete['new_prod_list'].isin(product_list_3)\n",
    "baskets_prod3 = baskets_complete.loc[mask_prod3]\n",
    "# pivot the dataset\n",
    "basket_matrix_3 = (baskets_prod3.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_4 = product_list[3000:]\n",
    "mask_prod4 = baskets_complete['new_prod_list'].isin(product_list_4)\n",
    "baskets_prod4 = baskets_complete.loc[mask_prod4]\n",
    "# pivot the dataset\n",
    "basket_matrix_4 = (baskets_prod4.groupby(['order_id', 'new_prod_list'])['all_ones']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('order_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's merge all the small dataframes into a large one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basket_matrix_1.shape)\n",
    "print(basket_matrix_2.shape)\n",
    "print(basket_matrix_3.shape)\n",
    "print(basket_matrix_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = basket_matrix_1.merge(basket_matrix_2, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = matrix1.merge(basket_matrix_3, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_matrix_usr = matrix2.merge(basket_matrix_4, \n",
    "                      how='outer', \n",
    "                      on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_matrix_usr.to_csv('../../data/03_processed/basket_matrix_usr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model in a file located in src data folder and read the result into the data 05_model output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = pd.read_csv('../../data/05_model_output/data_matrix_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_matrix.loc['yoghurt'].nlargest(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**:\n",
    "\n",
    "* https://medium.com/datadriveninvestor/how-to-build-a-recommendation-system-for-purchase-data-step-by-step-d6d7a78800b6\n",
    "* http://www.moorissatjokro.com/#home\n",
    "* https://towardsdatascience.com/how-to-build-a-simple-recommender-system-in-python-375093c3fb7d\n",
    "* **Possible Algorithm to use**: https://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering\n",
    "* **Similairity Models**: https://surprise.readthedocs.io/en/stable/similarities.html\n",
    "* **Association Rule Learning**: https://en.wikipedia.org/wiki/Association_rule_learning\n",
    "* collaborative filtering item - item article medium: https://medium.com/radon-dev/item-item-collaborative-filtering-with-binary-or-unary-data-e8f0b465b2c3\n",
    "* **How to use Pyspark and AWS**: https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921\n",
    "* **association rule algorithm**: https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "* **appriori**: https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "\n",
    "***\n",
    "* **Practical Business Python**: https://pbpython.com/market-basket-analysis.html\n",
    "* **Market Basket Analysis Notebook**: https://github.com/chris1610/pbpython/blob/master/notebooks/Market_Basket_Intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory-based methods**\n",
    "1. **User-based collaborative filtering**: In this model products are recommended to a user based on the fact that the products have been liked by users similar to the user. For example if Derrick and Dennis like the same movies and a new movie comes out that Derick likes,then we can recommend that movie to Dennis because Derrick and Dennis seem to like the same movies.\n",
    "1. **Item-based collaborative filtering**: These systems identify similar items based on users’ previous ratings. For example if users A,B and C gave a 5 star rating to books X and Y then when a user D buys book Y they also get a recommendation to purchase book X because the system identifies book X and Y as similar based on the ratings of users A,B and C."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
